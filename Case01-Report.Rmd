---
title: \vspace{-1.0cm} Particle Clustering in Turbulence Case Report
author: "Jack Lichtenstein, Abbey List, Jingxuan Liu, Linda Tang, Mary Wang, and Justin Zhao"
output:
  pdf_document: default
header-includes:
- \usepackage[labelformat = empty]{caption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning=F)
```

```{r load-library}
library(tidyverse)
library(here)
library(splines)
library(broom)
library(knitr)
library(kableExtra)
library(patchwork)
library(car)
theme_set(theme_light()) # setting a theme
```

```{r load-data}
# remember to set working directory
train <- read.csv("data/data-train.csv")
test <- read.csv("data/data-test.csv")
```

```{r setup-moments}
train <- train %>%
  dplyr::mutate(
    central_1 = R_moment_1, #mean
    central_2 = R_moment_2 - R_moment_1^2, #var
    central_3 = (R_moment_3 - 3*R_moment_2*R_moment_1 + 2*R_moment_1^3), #skew
    central_4 = (R_moment_4 - 4*R_moment_3*R_moment_1 + 6*R_moment_2*R_moment_1^2 - 3*R_moment_1^4)) #kurtosis
```

### 1 Introduction 

Turbulence is a fundamental concept in fluid mechanics. Irregular, unpredictable, and energy-dissipating, turbulent flow enhances mixing, which leads to non-uniform distribution of particles and cluster formation. Understanding and predicting turbulence has great practical significance in many scientific areas including aeronautical engineering and environmental science.

Existing research suggests that the clustering of particles subject to turbulent flow is mainly determined by three main parameters: Reynolds (Re) number, Froude (Fr) number and Stokes (St) number, which correspond to the intensity of turbulence, impact of gravitational acceleration, and particle size properties (Chanson, 2009; Ireland et al., 2016). These parameters may influence clustering individually; a large $St$, for example, correlates with large particle size, which tends to form relatively loose clusters (Ireland et al., 2016). The parameters may also interact with each other to impact cluster formation (e.g. Zamansky, 2013).

Despite the importance of turbulence, current understanding of *how* Re, Fr, and St contribute to clustering remains rudimentary. Simulation methods like the Direct Numerical Simulation (DNS) of Navier-Stokes equations have been applied, but progress is limited by the time-consuming and computationally-expensive nature of such methodologies (Moin & Mahesh, 1998). Leveraging generated data, the present study *aims* to build a statistical model that investigates how Re, Fr and St influence particle cluster volume distribution. We hope that our model will 1) enhance our understanding of the relative influence of these parameters in turbulent flow, and 2) enable an efficient and accurate prediction of a particle cluster volume distribution without the need for simulation.

### 2 Methods

#### 2.1 Data

The data (*n* = 89) for the present study come from Direct Numerical Simulation. Voronoi Tessellation, a technique that examines general features of individual clusters in the underlying turbulence, was applied to generate a distribution of cluster volumes. The original data contains information regarding the generated distributions in the form of the first four raw moments $\mathbb E(X)$, $\mathbb E(X^2)$, $\mathbb E(X^3)$, and $\mathbb E(X^4)$, as well as Re, Fr, and St values. 

For better interpretability, we transformed the 2nd, 3rd, and 4th raw moments into central moments (Moment 1 is untouched as it already signifies the mean), which are related to the variance (how flow varies over time), skewness (indication of symmetric properties of the flow), and kurtosis of the distribution (how particular cluster volumes deviate). In addition, despite their numerical natures, Fr and Re only contain three levels ($Fr \in \{0.052, 0.3, \inf\}$ and $Re \in \{90, 224, 398\}$, see Figure S1 for distribution) in the training data. We decided to model them as categorical variables because 1) treating them as numeric variables puts our model at risk for extrapolation due to lack of data at many levels of Re and Fr, making our model unable to learn the trends around such regions and 2) we believe that these categories could carry some real life significance. For instance, Fr = 0.3 is representative of cumulonimbus clouds and 0.052 is representative of cumulus clouds. Focusing on observations collected at such specific levels may lend unique insights into practical problems. 

#### 2.2 Model Construction

A closer examination of the data revealed interesting interactive patterns among the independent and dependent variables. Specifically, $St$ appears to assume a strong, non-linear relationship with each of the moments (Figures S1-S4 in the Appendix). These relationships vary between roughly linear to noticeably curved, potentially quadratic or cubic. In addition, such relationships diverge across different moments, and appear highly influenced by the combined levels of $Re$ and $Fr$. From the curved shape of the relationship between $St$ and the responses, we also noticed that linearity may be improved by taking certain roots of $St$. 

Given the paucity of theoretical background in related fields to guide model building, we decided to adopt a k-fold cross validation approach. This approach would allow us to explore different combinations of polynomial patterns and the interactions observed in our EDA and select the best fit model. Specifically, we used K = 5 given the small sample size at hand to avoid overfitting. We also decided to build linear models, as they are easy to interpret and could provide relatively straightforward indications on the relationship between our predictors and outcomes. 

To implement the k-fold cross validation, for each moment, we trained candidate models to predict the moment with the general formula $Moment_i \sim poly(St_i^{(1/root)} , degree)*(Fr, Re)$, varying the *degree* parameter from 1 to 3, *root* from 1 to 6, and testing a log transformation of the response. Literature supports a logarithmic dependence of acceleration on the Reynolds number (Zamansky, 2013); thus, we combined $Fr$ and $Re$ to form a new interaction variable $(Fr, Re)$ with 9 levels representing all combinations of $Fr$ and $Re$ in our data. We tested the model on each fold, and chose the parameters that gave lower root mean squared errors (See Figure 1), with preference for less complexity if the error is similar. After selecting the features for each moment's model, we then fit the final models on the full training dataset. 

```{r factors, echo=FALSE}
# make Fr, Re factors
train <- train %>%
  mutate(Fr.numeric = 2/pi*atan(Fr), Re.numeric = Re) %>%
  dplyr::mutate(dplyr::across(c(Fr, Re), factor))
```

```{r cv folds}
# split into train and test
set.seed(123)
train$index <- 1:nrow(train)
spl <- rsample::initial_split(train, prop = 0.8)
tr <- rsample::training(spl)
te <- rsample::testing(spl)
# create folds
set.seed(234)
folds <- rsample::vfold_cv(tr, v = 5)
```

```{r cv lm, echo=FALSE}
# function to train on a given fold, using given degree, predicting given moment
lm_cv <- function(fold, degree, moment, root = 2, log = TRUE) {
  data <- rsample::analysis(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  assess <- rsample::assessment(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  
  data <- data %>%
    dplyr::mutate(St = St^(1/root))
  assess <- assess %>%
    dplyr::mutate(St = St^(1/root))
  
  if (isTRUE(log)) {
    data <- data %>%
      dplyr::mutate(target = log(target))
    assess <- assess
  }
  
  mod <- data %>%
    lm(target ~ poly(St, degree)*interaction, data = .)
  assess <- assess %>%
    dplyr::mutate(pred = predict(mod, ., type = "response") %>% as.numeric())
  
  if (isTRUE(log)) {
    assess <- assess %>%
      dplyr::mutate(pred = exp(pred))
  }
  return(assess)
}
```

```{r cv perform, echo=FALSE}
# compute CV
cv <- tidyr::crossing(fold = 1:5,
                      degree = 1:3,
                      moment = 1:4,
                      root = 1:6,
                      log = c(FALSE)) %>%
  dplyr::mutate(cv = purrr::pmap(list(fold, degree, moment, root, log),
                                 ~ lm_cv(fold = ..1,
                                         degree = ..2,
                                         moment = ..3,
                                         root = ..4,
                                         log = ..5))) %>%
  tidyr::unnest(cv)
```

```{r, fig.height = 3, echo=FALSE, fig.cap = "\\textbf{Figure 1.} Root mean squared error and mean adjusted r-squared value of models for each moment with varying root and polynomial degrees on St. The combination that lead to the lowest root mean squared error was selected as the final model for the moment."}

# transform cv to wide format
cv_wide <- cv %>% 
  dplyr::transmute(index, fold, degree, root, log, 
                   moment = paste0("central_", moment), 
                   pred) %>% 
  tidyr::pivot_wider(names_from = moment,
                     values_from = pred)
# undo central moments
cv_summarized <- cv_wide %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4) %>% 
  # pivot back longer
  tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                      names_to = "moment",
                      values_to = "pred") %>% 
  # join in actual values for each moment
  dplyr::left_join(train %>% 
                     dplyr::select(index, dplyr::starts_with("R_moment_")) %>% 
                     tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                                         names_to = "moment",
                                         values_to = "target"),
                   by = c("index", "moment")) %>% 
  dplyr::group_by(moment = factor(moment), degree, root, log) %>%
  dplyr::summarise(rmse = sqrt(mean((pred-target)^2)),
                   broom::glance(lm(target ~ pred, data = dplyr::cur_data())),
                   .groups = "drop") 
# plot results
ar2 <- cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>% 
  filter(name == "adj.r.squared")

rmse <- cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>% 
  filter(name == "rmse")

p1 <- ggplot(data = rmse, aes(root, value, color = as.factor(degree))) +
  geom_line(legend = F) +
  geom_point(show.legned = F) +
  facet_wrap(~ type, scales = "free", ncol = 4) +
  labs(x = "Root Degree",
       y = NULL,
       color = "Polynomial Degree") + 
  theme(legend.title = element_text(size = 5), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))

p2 <- ggplot(data = ar2, aes(root, value, color = as.factor(degree))) +
  geom_line(legend = F) +
  geom_point(show.legned = F) +
  facet_wrap(~ type, scales = "free", ncol = 4) +
  labs(x = "Root Degree",
       y = NULL,
       color = "Polynomial Degree") + 
  theme(legend.title = element_text(size = 5), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))

p1 / p2 + plot_layout(guides = 'collect')
```

Based on the k-fold cross-validation approach, the final models for each moment are as below:

$$\text{Raw Moment}_1 \sim St*(Fr, Re)$$
$$\text{Central Moment}_2 \sim \text{poly}(St^{1/4}, 2) * (Fr, Re)$$
$$\text{Central Moment}_3 \sim \text{poly}(St^{1/3}, 2) * (Fr, Re)$$
$$\text{Central Moment}_4 \sim \text{poly}(\sqrt{St}, 2) * (Fr, Re)$$

The linearity, constant variance, and independence assumptions for linear regression are satisfied, and no serious concerns of multicollinearity was found. We observed some violations of normality, as well as a few outliers and influential points. For further details on model diagnostics, please refer to the Appendix. 

#### 2.3 Model Extension

Despite certain advantages in modeling $Re$ and $Fr$ as categorical variables, we recognize the need to extrapolate beyond the three levels of $Re$ and $Fr$ to model real life circumstances and enable a wider range of prediction. To address the limitations of our current models, we provide the following related models using natural splines that can be used for extrapolation: 

$$\text{Raw Moment}_1 \sim \text{ns}(St, df=1)*Re*Fr'$$
$$\text{Raw Moment}_{2,3,4} \sim \text{ns}(\sqrt{St}, df=1)*Re*Fr'$$
In these models, $Re$ is numeric and $Fr$ is transformed to a numeric variable on $[0, 1]$ using $Fr' = \frac{2}{\pi}*arctan(Fr)$. The form is similar in keeping the significant three-way interaction, except with natural splines to address the poor fits of polynomials at the tails, a location that is especially important in learning about particle behavior in high turbulence. Again, the root and degree are chosen through 5-fold cross validation. See Appendix for fitted coefficients.

### 3 Results

Selected outputs from the final models of each moment are displayed in Table 1. Please refer to Table S1 for the error values for the final models and Tables S2-S5 for full outputs.

```{r}
# potential outlers: 82 / 80, 85
model1 <- train %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_1 ~ poly(St, 1)*interaction, data = .)
# summary(model1)
#kableExtra::kable(tidy(model1), format = "markdown", digits = 3, 
  #                caption = "Moment 1 Results")
#plot(model1)
```

```{r}
# potential outliers: 20, 65
model2 <- train %>%
  mutate(St = St^(1/4)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_2 ~ poly(St, 2)*interaction, data = .)
#summary(model2)
#kableExtra::kable(tidy(model2), format = "markdown", digits = 3, 
     #             caption = "Moment 2 Results")
#plot(model2)
```

```{r}
# potential outliers: 79, 20
model3 <- train %>%
  mutate(St = St^(1/3)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_3 ~ poly(St, 2)*interaction, data = .)
#summary(model3)
#kableExtra::kable(tidy(model3), format = "markdown", digits = 3, 
       #           caption = "Moment 3 Results")
#plot(model3)
```

```{r Table 1}
#potential outliers: 79
model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_4 ~ poly(St, 2)*interaction, data = .)
#summary(model4)
#kableExtra::kable(tidy(model4), format = "markdown", digits = 3, 
       #           caption = "Moment 4 Results")
#plot(model4)
model1.sig <- tidy(model1, conf.int = TRUE, conf.level = 0.95) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  )) %>%
  dplyr::select(-std.error, -statistic)

model2.sig <- tidy(model2, conf.int = TRUE, conf.level = 0.95) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  )) %>%
  dplyr::select(-std.error, -statistic)

model3.sig <- tidy(model3, conf.int = TRUE, conf.level = 0.95) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  )) %>%
  dplyr::select(-std.error, -statistic)

model4.sig <- tidy(model4, conf.int = TRUE, conf.level = 0.95) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  )) %>%
  dplyr::select(-std.error, -statistic)

```

```{r}
mod.1 <- c("Moment 1", "", "", "", "")
mod.2 <- c("Moment 2", "", "", "", "")
mod.3 <- c("Moment 3", "", "", "", "")
mod.4 <- c("Moment 4", "", "", "", "")
Table_combined <- as.data.frame(rbind(mod.1, model1.sig, mod.2, model2.sig, mod.3, model3.sig, mod.4, model4.sig))
Table_combined[1,1] <- cell_spec(Table_combined[1,1], bold = T)
Table_combined[8,1] <- cell_spec(Table_combined[8,1], bold = T)
Table_combined[12,1] <- cell_spec(Table_combined[12,1], bold = T)
Table_combined[16,1] <- cell_spec(Table_combined[16,1], bold = T)
 kable(Table_combined, format = "latex", 
        escape = F, booktabs = T, longtable=T, linesep = NULL,
        col.names = c(
          "Term", "$\\beta$", "$p$ value", "95 CI Lower", "95 CI Upper"
        )) %>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Outputs from final models of each moment. Only the significant terms are displayed here given limited space. Please refer to Tables S2-S5 in Appendix for full output.",
           general_title = "Table 1.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r predict on holdout}
test <- test %>% 
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
# central 1
test$central_1 = test %>% 
  predict(model1, ., type = "response")
# central 2
test$central_2 = test %>%
  mutate(St = St^(1/4)) %>%
  predict(model2, ., type = "response")
# central 3
test$central_3 = test %>%
  mutate(St = St^(1/3)) %>%
  predict(model3, ., type = "response")
# central 4
test$central_4 = test %>%
  mutate(St = sqrt(St)) %>%
  predict(model4, ., type = "response")
test <- test %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4)
# write.csv(test, file="data/data-test_pred.csv")
```

Firstly, all models possess an adjusted $R^2$ of at least 0.98 (See Table S1), indicating that at least 98% of the variation in each centralized moment is explained by the predictors in the models. The test error (modeled by root mean squared error) from $k$-fold cross validation is only 0.00764 and 20.86 for models of centralized moments 1 and 2, respectively. Although the values are larger for models of centralized moments 3 and 4 (above 200,000 and above 1 million, respectively), this is expected given the extremely large variation in these moments. Overall, these metrics indicate that our model has good predictive power. 

To better understand the relative influence of turbulence, gravitational acceleration and particle characteristics on cluster formation, we examined the model coefficients. For centralized moment 1, we see that interactions between all settings of Fr and the lowest setting of Re, along with their interactions with St, yield an expected increase in mean particle cluster volume size. This suggests that smoother flow at any level of gravitational acceleration and particle size may allow larger clusters to form, as they are not broken up by chaotic turbulence. These coefficients are statistically significant at the $\alpha = 0.01$ level with small standard errors. For centralized moments 2, 3, and 4, the interactions between the level of lowest Fr (90) and lowest Re (0.052) and $St^1/2$, as well as with $St$, both turns out significant. Taken together, this suggests that at Fr = 90 and Re = 0.052, the variance, skew, and kurtoisis (distributional "tailedness") of the cluster distribution are impacted differentially by particle size than at the other combination levels. 

<!-- This indicates that smoother flow and low gravitational acceleration are associated with greater variance, skew, and kurtosis (distributional "tailedness") of particle cluster size. The effect of particle size at these levels of Re and Fr may differ from the effect at other levels, as it is only statistically significant at these low settings of flow intensity and gravitational acceleration. These coefficients are statistically significant at the $\alpha = 0.01$ level. has a positive association with each moment. The interaction with squared St has a negative association with each moment (note that the exact value of this squared transformation differs based on the root transformation applied to St for each moment) -->

### Discussion

In this study, we constructed four linear models with polynomial terms and interaction terms between Reynolds' number, Froude's number, and Stokes' number to predict the first four centralized moments (related to mean, variance, skew, and kurtosis) of particle cluster distribution. Our models were able to explain a large percentage of variation in each of the four moments with reasonable mean squared prediction error for each model. We found that smoother flow at any level of gravitational acceleration and particle size may be associated with larger mean cluster size, and smoother flow with low gravitational acceleration seemed to have a positive association with variance, skew, and kurtosis. Finally, the effects of particle size on each moment seemed to be significantly different at lower flow intensity and lower gravitational acceleration than at other settings. This is especially salient for centralized moments 2-4, which appears to assume different relationships with particle size at the lowest values of $Fr$ and $St$. Such findings may have real world implications, as the levels are tied to some natural phenomena (e.g. culumus clouds are often found at $Fr = 0.052$)

One limitation of our analysis is that the coefficient estimates may not be accurate for our models since the 95% confidence intervals are relatively wide. This likely results from having a small training set with less than 100 data points. In addition, the normality assumption of linear regression is violated due to the extreme skewness/variation of the moments and several outliers for each model. Our training set may not be a representative sample that allows our model to learn the underlying trend and model the highly complex distribution of the moments. We recommend using caution in interpreting the exact coefficient estimates. 

Furthermore, Fr and Re were used as categorical variables in our models despite that they take on numeric values in practice. This approach limits the generlizability of our model since it cannot be applied on values outside the categories. We attempt to address this limitation by building a natural spline model while treating Fr and Re as numeric variables to allow for extrapolation. However, the predictive power of this model has not been thoroughly assessed, and this model likely requires a much larger training set to fit well.

In addition, given the training set, our model was only fit on Reynolds numbers up to 398, although numbers in the thousands are common in practice. Large Reynolds numbers are highly relevant to real life situations as a measure of turbulence intensity in atmospheric, oceanic turbulence flow (J. den Toonder et al., 1997).  Although our modeling approach avoids the high computational cost of simulation at large Reynolds numbers, it may not be suitable for extrapolation at these settings. Using numerical variables and higher Reynolds numbers may be topics for further investigation. 

In summary, our models assessed the effects of Reynolds, Froude, and Stokes numbers on particle cluster size and can be used in predicting particle cluster volume distribution given certain restrictions. We hope our results could inform further research on understanding particle clustering in turbulence and improve the efficiency of prediction. 

\newpage

## References

- J. M. J.  den Toonder, &amp; Nieuwstadt, F. T. M. (1997, November 1). Reynolds number effects in a turbulent pipe flow for low to moderate re. AIP Publishing. Retrieved October 12, 2021, from https://aip.scitation.org/doi/pdf/10.1063/1.869451. 

- Schlichting, H., Gersten, K., Krause, E., &amp; Oertel, H. (2017). Boundary-layer theory. Springer. 

- Chanson, Hubert (2009). "Development of the Bélanger Equation and Backwater Equation by Jean-Baptiste Bélanger (1828)" (PDF). Journal of Hydraulic Engineering. 135 (3): 159–63. doi:10.1061/(ASCE)0733-9429(2009)135:3(159).

- Ireland, P. J., Bragg, A. D., &amp; Collins, L. R. (2016, May 11). The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. part&nbsp;2. simulations with gravitational effects: Journal of Fluid Mechanics. Cambridge Core. Retrieved October 12, 2021, from https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/effect-of-reynolds-number-on-inertial-particle-dynamics-in-isotropic-turbulence-part-2-simulations-with-gravitational-effects/67C55CDC28B1B1C7868B7A402E279AF9. 

- Moin, P., &amp; Mahesh, K. (n.d.). Direct numerical simulation: A tool in turbulence research. Annual Reviews. Retrieved October 12, 2021, from https://www.annualreviews.org/doi/full/10.1146/annurev.fluid.30.1.539. 

- Zamansky, R., Vinkovic, I., &amp; Gorokhovski, M. 2013. Acceleration in turbulent channel flow: universalities in statistics, subgrid stochastic models and an application. Journal of Fluid Mechanics. Retrieved October 14, 2021, from https://hal.archives-ouvertes.fr/hal-00931506/document.  

- slides: https://sakai.duke.edu/access/content/group/e1e1b166-17bd-4efc-bdfb-f3909d696910/Case%20Study/Data_Expedition_F2020_Reza_Jon.pdf

\newpage


## Appendix 

### Section A: Tables 

Model outputs are shown below: 

```{r table-s1 cv results}
tableS1 <- cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>% 
  dplyr::group_by(moment, name) %>% 
  dplyr::mutate(best = ifelse(name == "adj.r.squared", max(value), min(value))) %>% 
  ungroup() %>% 
  filter(value == best) %>% 
  select(moment, degree, root, log, name, value) %>% 
  mutate(value = scales::comma(value, accuracy = 0.00001)) 
 
colnames(tableS1) <- c("Moment", "Degree", "Root", "Log", "Name", "Value")
# 
# kable(tableS1, format = "markdown", caption = "Errors from final models for each moment")

kable(tableS1, booktabs = T)%>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "Errors from final models for each moment",
            general_title = "Table S1.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```

```{r table-s2}
mod1 <- tidy(model1) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  ))
 kable(mod1, booktabs = T, escape = F, linesep = NULL, col.names = c(
           "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
         ))%>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "Full output of the final model for predicting Moment One",
            general_title = "Table S2.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```

```{r table-s3}
mod2 <- tidy(model2) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 
 kable(mod2, booktabs = T, escape = F, linesep = NULL, col.names = c(
           "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
         ))%>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "Full output of the final model for predicting Central Moment Two",
            general_title = "Table S3.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```

```{r table-s4}
mod3 <- tidy(model3) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 
 kable(mod3, booktabs = T, escape = F, linesep = NULL, col.names = c(
           "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
         ))%>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "Full output of the final model for predicting Central Moment Three",
            general_title = "Table S4.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```

```{r table-s5}
mod4 <- tidy(model4) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 

 kable(mod4, booktabs = T, escape = F, linesep = NULL, col.names = c(
           "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
         ))%>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "Full output of the final model for predicting Central Moment Five",
            general_title = "Table S5.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```


```{r Table S6, eval = T}
# Note: don't perform as well because splines tend to require more data to fit + extrapolation means more uncertainty generally

model_1 <- train %>%
  lm(R_moment_1 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
model_2 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_2 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
model_3 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_3 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
model_4 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_4 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)

model_1 <- tidy(model_1)%>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

model_2 <- tidy(model_2)%>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

model_3 <- tidy(model_3) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

model_4 <- tidy(model_4)%>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

spline.table <- rbind(mod.1, model_1, mod.2, model_2,mod.3,  model_3, mod.4, model_4)

spline.table[1,1] <- cell_spec(spline.table[1,1], bold = T)
spline.table[10,1] <- cell_spec(spline.table[10,1], bold = T)
spline.table[19,1] <- cell_spec(spline.table[19,1], bold = T)
spline.table[28,1] <- cell_spec(spline.table[28,1], bold = T)
 kable(spline.table, format = "latex", 
        escape = F, booktabs = T, longtable=T, linesep = NULL,
        col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        )) %>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Outputs from the spline model from Section 2.4.",
           general_title = "Table S6.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r}
# Should we include them?

# train %>%
#   ggplot(aes(x = St, y = R_moment_1, color = interaction(Re,Fr))) +
#   geom_point()
# train %>%
#   ggplot(aes(x = St, y = central_2, color = interaction(Re,Fr))) +
#   geom_point()
# train %>%
#   ggplot(aes(x = St, y = central_3, color = interaction(Re,Fr))) +
#   geom_point()
# train %>%
#   ggplot(aes(x = St, y = central_4, color = interaction(Re,Fr))) +
#   geom_point()
```

### Section B: Figures 

```{r fig-S1, fig.height = 3, fig.width=8, fig.cap="\\textbf{Figure S1.} Distribution of the three levels of Re and Fr. The values are treated as factor levels in our main analysis."}
# histograms of predictors
tr %>%
  pivot_longer(cols = c(Re:Fr),
               names_to = "metric",
               values_to = "value") %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 20, stat = "Count") +
  facet_wrap(~ metric, scales = "free") + 
  labs(x = "Value", y = "Count") + 
  theme(axis.text = element_text(size = 6))
```

\hfill\break

```{r Figure-S2, fig.height = 3.5, fig.cap = "\\textbf{Figure S2.} Moment 1 values as a function of St at different levels of interaction between Fr and Re."}
tr %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Moment 1", color = "Fr:Re") + 
  theme(legend.title = element_text(size = 7), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 6), 
        strip.text.x = element_text(size = 5))
```

\hfill\break

```{r Figure-S3, fig.height = 3.5, fig.cap = "\\textbf{Figure S3.} Central Moment 2 values as a function of St at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_2, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 2", color = "Fr:Re") +
  theme(legend.title = element_text(size = 7), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))
```

\hfill\break

```{r Figure-S4, fig.height = 3.5, fig.cap = "\\textbf{Figure S4.} Central Moment 3 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_3, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 3", color = "Fr:Re") + 
  theme(legend.title = element_text(size = 7), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))
```

\hfill\break

```{r Figure-S5, fig.height = 3.5, fig.cap = "\\textbf{Figure S5.} Central Moment 4 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_4, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 4", color = "Fr:Re") + 
    theme(legend.title = element_text(size = 7), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))
```

\newpage

### Section C: Model Diagnoistics

**Modeling assumptions for linear regression**: 

* **Linearity**: Linearity is satisfied for all 4 models since in the predicted vs. standardized residuals plots (Panel A), there's no obvious pattern in the residuals are the value of the predictors increase. The residuals are randomly scattered around 0, supporting that there's a linear relationship between the predictors and the response (after variable transformation). 
* **Constant variance**: In the residuals vs. predicted plot for all 4 models, the vertical spread of the residual remain relatively constant as the predicted values increases, suggesting that the variance of the error is constant along all predicted values (Panel A). 
* **Independence**: The data was generated from Direct Numerical Stimulation (DNS) of the Navier-Stokes equations, where each trial was conducted independently using different values of the parameter (Re, Fr, St). Based on the information about data collection, we believe the independence assumption is satisfied.
* **Normality**: Normality may be violated since the distribution of the residuals doesn't follow a normal distribution and the points do not fall along a straight diagonal line on the normal quantile plot. The flat region in the normal quantile plot indicates there's a lot of nearly identical values, and the curved shape suggests that the distribution may be heavy-tailed. This violation makes sense in the context of the dataset since we observed that both the raw moments and central moments are highly skewed to the right with most values close to 0 with some extreme outliers (Panel B). 

**Influential points and outliers**: We assessed influential points in our dataset using Cook's distance (Panel C). Besides having a few influential points for model 1, all observations had Cook's distance less than 0.5 for the rest of the models. In addition, from the predicted vs. standardized residuals plots (Panel A), there are only a few outliers with standardized residual greater than 5.

**Multicolinearity**: We assessed multicolinearity using generalized variance inflation factor (GVIF) accounting for the degree of freedom, which was below 5 for all predictors in all 4 models, suggesting no serious issue of multicolinearity. 

```{r diag}
diag_plot <- function(model) {
  
  model_aug <- augment(model) %>%
    mutate(obs_num = row_number())

  resid_fitted <- ggplot(data = model_aug, aes(x = .fitted, y = .std.resid)) +
    geom_point(alpha = 0.7) +
    #geom_hline(yintercept = c(-2, 2), color = "blue", lty = 2) +
    geom_hline(yintercept = c(-3, 3), color = "red", lty = 3) +
    labs(x = "Predicted values",
         y = "Standardized Residual",
         title = "Fitted vs. Standardized Residual") +
    theme_bw() +
    theme(plot.title = element_text(size = 8),
          axis.title = element_text(size = 6),
          axis.text = element_text(size = 5))

  resid_qq <- ggplot(data = model, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() +
  labs(title = "Normal Quantile plot of residuals") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6), 
          axis.text = element_text(size = 5))
  
  cook <- ggplot(data = model_aug, aes(x = obs_num, y = .cooksd)) + 
    geom_point(alpha = 0.7) + 
    geom_hline(yintercept = 0.5, color = "blue", lty = 2) +
    geom_hline(yintercept = 1, color = "red", lty = 3) +
    labs(x = "Observation Number", y = "Cook's distance") +
    geom_text(aes(label = ifelse(.hat > 1,
                               as.character(obs_num), "")), nudge_x = 4) + 
    labs(title = "Observation number vs. Cook's distance") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6), 
          axis.text = element_text(size = 5))
  
  resid_fitted / (resid_qq + cook) + 
    plot_annotation(tag_levels = 'A') & theme(plot.tag = element_text(size = 8))
}
```

```{r Diag Model 1, fig.height = 4, fig.cap = "\\textbf{Figure S6.} Diagnoistic plots for model predicting Moment 1."}
diag_plot(model1)
```

```{r Diag Model 2, fig.height = 4, fig.cap = "\\textbf{Figure S7.} Diagnoistic plots for model predicting Moment 2."}
diag_plot(model2)
```

```{r Diag Model 3, fig.height = 4, fig.cap = "\\textbf{Figure S8.} Diagnoistic plots for model predicting Moment 3."}
diag_plot(model3)
```

```{r Diag Model 4, fig.height = 4, fig.cap = "\\textbf{Figure S9.} Diagnoistic plots for model predicting Moment 4."}
diag_plot(model4)
```

```{r}
`Model Name` <- c("model 1", "model 1", "model 1",
                  "model 2", "model 2", "model 2",
                  "model 3", "model 3", "model 3",
                  "model 4", "model 4", "model 4")

VIF_all <- rbind(round(vif(model1), 3), round(vif(model2), 3), 
                 round(vif(model3), 3), round(vif(model4), 3)) %>% 
  cbind(`Model Name`) 
colnames(VIF_all) <- c("GVIF", "DF", "GVIF (adjusted for DF)", "Model")

kable(VIF_all, format = "markdown") %>% 
   kable_styling(position = "center")  %>% 
   footnote(general = "The variable inflation factor (VIF) for all model coefficients",
            general_title = "Table S6.",
            footnote_as_chunk = TRUE,
            title_format = "bold",
            escape = FALSE,
            threeparttable = TRUE)
```
