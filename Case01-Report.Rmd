---
title: "Case Report"
author: "Jack Lichtenstein, Abbey List, Jingxuan Liu, Linda Tang, Mary Wang, and Justin Zhao"
date: "`r Sys.Date()`"
output:
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning=F)
```

```{r load-library}
library(tidyverse)
library(here)
library(splines)
theme_set(theme_light()) # setting a theme
```

```{r load-data}
# remember to set working directory
train <- read.csv("data/data-train.csv")
test <- read.csv("data/data-test.csv")
```

```{r setup-moments}
train <- train %>%
  mutate(
    central_1 = R_moment_1, #mean
    central_2 = R_moment_2 - R_moment_1^2, #var
    central_3 = (R_moment_3 - 3*R_moment_2*R_moment_1 + 2*R_moment_1^3), #skew
    central_4 = (R_moment_4 - 4*R_moment_3*R_moment_1 + 6*R_moment_2*R_moment_1^2 - 3*R_moment_1^4)) #kurtosis
```

## 1 Introduction 

Turbulence is a fundamental concept in fluid mechanics. Understanding how fluids move has enormous importance to a vast range of problems, with practical applications in aeronautical engineering, environmental science, astronomy, and more. In contrast to laminar flow, turbulent flow is irregular, unpredictable, and energy-dissipating. Turbulence enhances mixing which leads to non-uniform distribution of particles and cluster formation. In general, the final state of particles subject to turbulent flow is determined by three main parameters: Reynolds (Re) number, Froude (Fr) number and Stokes (St) number. The Reynolds number is a measure of the intensity of turbulence, with a higher Reynolds number corresponding to a higher intensity of turbulence (J. den Toonder et al., 1997). Broadly speaking, a Reynolds number > 4000 generally represents a relatively chaotic and turbulent flow, a Reynolds number < 2300 generally represents a smooth laminar flow and any number in between typically represents transient flow (Schlichting et al., 2017). The Froude number is a measure of the impact of gravitational acceleration on fluid motion. For instance, a cumulonimbus cloud at a high level above the ground will have a smaller Froude number (compared to lower hanging stratus clouds) because it experiences a lower intensity of gravitational acceleration relative to other clouds (Chanson, 2009). Stokes number is a description of particle properties; a large Stokes number correlates with large particle size which tends to form relatively loose clusters (Ireland et al., 2016). 

Despite the importance of turbulence and particle clustering, we do not understand this process well very. Researchers has primarily used Direct Numerical Simulation (DNS) of Navier-Stokes equations to study this problem, but it is extremely time consuming and computationally expensive (Moin & Mahesh, 1998). In addition, the DNS method cannot be practically applied to simulate flows with large Reynolds numbers which requires high resolution, leading to long computation time. However, large Reynolds numbers is highly relevant to real life situations (atmospheric, oceanic turbulence flow). Thus, the primary research **objective** of this study is to build a statistical model to investigate how Reynolds (Re) number, Froude (Fr) number and Stokes (St) number influence particle cluster volume distribution and allows prediction without the need for simulation. 

The data for this study comes from Direct Numerical Simulation using a range of parameters. Then, Voronoi Tessellation, a technique that looks at general features of individual clusters in the underlying turbulence, has been applied to generate a distribution of cluster volumes. Since this probability distribution of cluster volumes is harder for statistical learning methods to work with, we will summarize this distribution by its first four raw moments $E(X)$, $E(X^2)$, $E(X^3)$, and $E(X^4)$, the latter three which we transform to central moments as response variables for inference and back for prediction. Theoretically, we are interested in the insights for each of these four moments - the mean of the distribution could be a good indicator of how flow behaves on average, the variance of the distribution could dictate how flow varies over time, the skew of the distribution could illustrate asymmetric properties of the flow, and the kurtosis of the distribution could indicate how particular cluster volumes deviate. We hope that our research model will enable a quick and efficient prediction of a particle cluster volume distribution and enhance our understanding of the relative influence of these parameters in turbulent flow.

## 2 Methods

### 2.1 Model

The forms of the statistical models, one for each moment, are:
$$R\_moment_1 \sim St*(Fr, Re)$$
$$central_2 \sim poly(St^{1/4}, 2) * (Fr, Re)$$
$$central_3 \sim poly(St^{1/3}, 2) * (Fr, Re)$$
$$central_4 \sim poly(\sqrt{St}, 2) * (Fr, Re)$$

where $Fr \in \{0.052, 0.3, \inf\}$ and $Re \in \{90, 224, 398\}$ are categorical variables and $(Fr, Re)$ is an interaction term with 9 levels representing all combinations of $Fr$ and $Re$. For the fitted coefficients, see the results section.

### 2.2 Justification

While $Fr$ and $Re$ are continuous values in physics, both variables contain only three levels in our training and test data (Appendix). Since we see from the test data that we are specifically interested in these levels, we treat both as categorical variables in modeling. For $Fr$ in particular, 0.3 represents cumulonimbus clouds and 0.052 represents cumulus clouds. See 2.4 for a separate model set that addresses these limitations. 

```{r factors, echo=FALSE}
# make Fr, Re factors
train <- train %>%
  mutate(Fr.numeric = 2/pi*atan(Fr), Re.numeric = Re) %>%
  dplyr::mutate(dplyr::across(c(Fr, Re), factor))
```

```{r cv folds}
# split into train and test
set.seed(123)
train$index <- 1:nrow(train)
spl <- rsample::initial_split(train, prop = 0.8)
tr <- rsample::training(spl)
te <- rsample::testing(spl)
# create folds
set.seed(234)
folds <- rsample::vfold_cv(tr, v = 5)
```

For other key properties, the three-way interaction between the predictors arises from exploratory data analysis where the relationship between $St$ and each moment appears highly influenced by the combined levels of $Re$ and $Fr$ (refer to Figures S1-S4 in the Appendix). In particular, this relationship varies between roughly linear to noticeably curved, potentially quadratic or cubic, and appears to be very strong. Additionally, we notice from the curved shape of the relationship between `St` and the response that we may benefit from taking certain roots of `St` to make that more linear.

### 2.2 Fitting Process

We used K-fold cross validation with $K=5$ to choose the model features, exploring linear regression and then nonlinear extensions into polynomial terms and interactions based on the EDA above. Since we only have 89 training observation, we do this in an effort to reduce the likelihood of overfitting.

Specifically, for each moment, we train candidate models to predict the moment with the general formula `~ poly(St^(1/root), degree)*(Fr, Re)`, varying the `degree` parameter from 1 to 3, varyind `root` from 1 to 6, and testing a log transformation of the response. We then look at the estimated test errors (see Figure x) and chose the parameters that give lower errors, with preference for less complexity if the error is similar. After selecting the features for each moment's model, we then fit the final models on the full training dataset using standard least-squares. (@Jing where to mention diagnostics)

```{r cv lm, echo=FALSE}
# function to train on a given fold, using given degree, predicting given moment
lm_cv <- function(fold, degree, moment, root = 2, log = TRUE) {
  data <- rsample::analysis(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  assess <- rsample::assessment(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  
  data <- data %>%
    dplyr::mutate(St = St^(1/root))
  assess <- assess %>%
    dplyr::mutate(St = St^(1/root))
  
  if (isTRUE(log)) {
    data <- data %>%
      dplyr::mutate(target = log(target))
    assess <- assess
  }
  
  mod <- data %>%
    lm(target ~ poly(St, degree)*interaction, data = .)
  assess <- assess %>%
    dplyr::mutate(pred = predict(mod, ., type = "response") %>% as.numeric())
  
  if (isTRUE(log)) {
    assess <- assess %>%
      dplyr::mutate(pred = exp(pred))
  }
  return(assess)
}
```

```{r cv perform, echo=FALSE}
# compute CV
cv <- tidyr::crossing(fold = 1:5,
                      degree = 1:3,
                      moment = 1:4,
                      root = 1:6,
                      log = c(FALSE)) %>%
  dplyr::mutate(cv = purrr::pmap(list(fold, degree, moment, root, log),
                                 ~ lm_cv(fold = ..1,
                                         degree = ..2,
                                         moment = ..3,
                                         root = ..4,
                                         log = ..5))) %>%
  tidyr::unnest(cv)
```

```{r, echo=FALSE}
# undo central
cv_wide <- cv %>%
    dplyr::group_by(index, fold, degree, root, log) %>%
    summarise(moment, pred)
  cv_wide <- cv_wide %>%
    reshape2::dcast(index + fold + degree + root + log ~ moment, value.var="pred")
  
  for (i in 1:nrow(cv_wide)) {
      cv_wide[i, "2"] = cv_wide[i, "2"] + cv_wide[i, "1"]^2
      cv[(cv["index"] == cv_wide[i, "index"]) & (cv["fold"] == cv_wide[i, "fold"]) & (cv["degree"] == cv_wide[i, "degree"]) & (cv["root"] == cv_wide[i, "root"]) & (cv["log"] == cv_wide[i, "log"]) & (cv["moment"] == 2), "pred"] = cv_wide[i, "2"] 
      cv_wide[i, "3"] = cv_wide[i, "3"] - 2*cv_wide[i, "1"]^3 + 3*cv_wide[i, "2"]*cv_wide[i, "1"]
      cv[(cv["index"] == cv_wide[i, "index"]) & (cv["fold"] == cv_wide[i, "fold"]) & (cv["degree"] == cv_wide[i, "degree"]) & (cv["root"] == cv_wide[i, "root"]) & (cv["log"] == cv_wide[i, "log"]) & (cv["moment"] == 3), "pred"] = cv_wide[i, "3"]
      cv_wide[i, "4"] = cv_wide[i, "4"] + 3*cv_wide[i, "1"]^4 - 6*cv_wide[i, "2"]*cv_wide[i, "1"]^2 + 4*cv_wide[i, "3"]*cv_wide[i, "1"]
      cv[(cv["index"] == cv_wide[i, "index"]) & (cv["fold"] == cv_wide[i, "fold"]) & (cv["degree"] == cv_wide[i, "degree"]) & (cv["root"] == cv_wide[i, "root"]) & (cv["log"] == cv_wide[i, "log"]) & (cv["moment"] == 4), "pred"] = cv_wide[i, "4"]
  }
  
cv_summarized <- cv %>%
  dplyr::group_by(moment = factor(moment), degree, root, log) %>%
  dplyr::summarise(rmse = sqrt(mean((pred-target)^2)),
                   mae = mean(abs(pred-target)),
                   broom::glance(lm(target ~ pred, data = dplyr::cur_data())),
                   .groups = "drop")
cv_summarized %>% 
  dplyr::filter(!(log)) %>% 
  dplyr::mutate(moment = paste0("Moment: ", moment)) %>%
  tidyr::pivot_longer(cols = c(rmse, mae, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>%
  ggplot(aes(root, value, color = as.factor(degree))) +
  geom_line() +
  geom_point() +
  facet_wrap(~ type, scales = "free", nrow = 4)
```

### 2.4 Model Extension

As noted above, extrapolating beyond the three levels of $Re$ and three levels of $Fr$ given may be useful for more general predictions and interpretation, since the actual variables have wide domains (@Jing how to word this). To deal with the limitations of our current models, we also provide the following related models that can be used for extrapolation: 

$$R\_moment_1 \sim ns(St, df=1)*Re*Fr'$$
$$R\_moment_2, R\_moment_3, R\_moment_3 \sim ns(\sqrt{St}, df=1)*Re*Fr'$$
In these models, $Re$ is numeric and $Fr$ is transformed to a numeric variable on $[0, 1]$ using $Fr' = \frac{2}{\pi}*arctan(Fr)$. The form is similar in keeping the significant three-way interaction, except with natural splines to address the poor fits of polynomials at the tails, a location that is especially important in learning about particle behavior in high turbulence. Again, the root and degree are chosen through 5-fold cross validation. See appendix for fitted coefficients.

## Results

Model Output:

```{r}
# potential outlers: 82 / 80, 85
model1 <- train %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_1 ~ poly(St, 1)*interaction, data = .)
summary(model1)
#plot(model1)
```

```{r}
# potential outliers: 20, 65
model2 <- train %>%
  mutate(St = St^(1/4)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_2 ~ poly(St, 2)*interaction, data = .)
summary(model2)
#plot(model2)
```

```{r}
# potential outliers: 79, 20
model3 <- train %>%
  mutate(St = St^(1/3)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_3 ~ poly(St, 2)*interaction, data = .)
summary(model3)
#plot(model3)
```

```{r}
#potential outliers: 79
model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_4 ~ poly(St, 2)*interaction, data = .)
summary(model4)
#plot(model4)
```

```{r}
test$R_moment_1 = test %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  predict(model1, ., type = "response")
test$R_moment_2 = test %>%
  mutate(St = St^(1/4)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  predict(model2, ., type = "response")
test$R_moment_3 = test %>%
  mutate(St = St^(1/3)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  predict(model3, ., type = "response")
test$R_moment_4 = test %>%
  mutate(St = sqrt(St)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  predict(model4, ., type = "response")

for (i in 1:nrow(test)) {
      test[i, "R_moment_2"] = test[i, "R_moment_2"] + test[i, "R_moment_1"]^2
      test[i, "R_moment_3"] = test[i, "R_moment_3"] - 2*test[i, "R_moment_1"]^3 + 3*test[i, "R_moment_2"]*test[i, "R_moment_1"]
      test[i, "R_moment_4"] = test[i, "R_moment_4"] + 3*test[i, "R_moment_1"]^4 - 6*test[i, "R_moment_2"]*test[i, "R_moment_1"]^2 + 4*test[i, "R_moment_3"]*test[i, "R_moment_1"]
}

write.csv(test, file="data/data-test_pred.csv")
```

## Discussion

\newpage

## References

- J. M. J.  den Toonder, &amp; Nieuwstadt, F. T. M. (1997, November 1). Reynolds number effects in a turbulent pipe flow for low to moderate re. AIP Publishing. Retrieved October 12, 2021, from https://aip.scitation.org/doi/pdf/10.1063/1.869451. 

- Schlichting, H., Gersten, K., Krause, E., &amp; Oertel, H. (2017). Boundary-layer theory. Springer. 

- Chanson, Hubert (2009). "Development of the Bélanger Equation and Backwater Equation by Jean-Baptiste Bélanger (1828)" (PDF). Journal of Hydraulic Engineering. 135 (3): 159–63. doi:10.1061/(ASCE)0733-9429(2009)135:3(159).

- Ireland, P. J., Bragg, A. D., &amp; Collins, L. R. (2016, May 11). The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. part&nbsp;2. simulations with gravitational effects: Journal of Fluid Mechanics. Cambridge Core. Retrieved October 12, 2021, from https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/effect-of-reynolds-number-on-inertial-particle-dynamics-in-isotropic-turbulence-part-2-simulations-with-gravitational-effects/67C55CDC28B1B1C7868B7A402E279AF9. 

- Moin, P., &amp; Mahesh, K. (n.d.). Direct numerical simulation: A tool in turbulence research. Annual Reviews. Retrieved October 12, 2021, from https://www.annualreviews.org/doi/full/10.1146/annurev.fluid.30.1.539. 

- slides: https://sakai.duke.edu/access/content/group/e1e1b166-17bd-4efc-bdfb-f3909d696910/Case%20Study/Data_Expedition_F2020_Reza_Jon.pdf

\newpage

## Appendix 

```{r hist pred, fig.height = 3, fig.width=8}
# histograms of predictors
tr %>%
  pivot_longer(cols = c(Re:Fr),
               names_to = "metric",
               values_to = "value") %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 20, stat="count") +
  facet_wrap(~ metric, scales = "free")
```

```{r eda plots, echo=FALSE, eval=FALSE}
tr_long <- tr %>%
  tidyr::pivot_longer(cols = starts_with("R_moment"),
               names_to = "moment",
               names_prefix = "R_moment_",
               values_to = "value") 
# plot St vs. R_moment_*, color by interaction between Fr, Re
tr_long %>%
  ggplot(aes(St, value, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ moment, scales = "free", labeller = label_both)
plot_moment <- function(mt) {
  tr_long %>%
    dplyr::filter(moment == mt) %>%
    ggplot(aes(St, value)) +
    geom_point() +
    geom_smooth() +
    facet_wrap(~ interaction(Fr, Re), scales = "free") +
    labs(title = paste0("Moment: ", mt))
}
cowplot::plot_grid(plot_moment("1"), plot_moment("2"), 
                   nrow = 1, ncol = 2)
cowplot::plot_grid(plot_moment("3"), plot_moment("4"), 
                   nrow = 1, ncol = 2)
```

```{r Figure-S1, fig.cap = "Moment 1 values as a function of particle size at different levels of interaction between Fr and Re."}
tr %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "Particle Size", y = "Moment 1", color = "Fr:Re")
```

```{r Figure-S2, fig.cap = "Moment 2 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_2, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "Particle Size", y = "Moment 2", color = "Fr:Re")
```

```{r Figure-S3, fig.cap = "Moment 3 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_3, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "Particle Size", y = "Moment 3", color = "Fr:Re")
```

```{r Figure-S4, fig.cap = "Moment 4 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_4, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "Particle Size", y = "Moment 4", color = "Fr:Re")
```

```{r cv results, echo=FALSE}
cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, mae, adj.r.squared)) %>% 
  dplyr::group_by(moment, name) %>% 
  dplyr::mutate(best = ifelse(name == "adj.r.squared", max(value), min(value))) %>% 
  dplyr::ungroup() %>% 
  dplyr::filter(value == best) %>% 
  dplyr::select(moment, degree, root, log, name, value) %>% 
  dplyr::mutate(value = scales::comma(value, accuracy = 0.00001)) %>% 
  kableExtra::kable(format = "markdown")
```

```{r}
# Note: don't perform as well because splines tend to require more data to fit + extrapolation means more uncertainty generally
model1 <- train %>%
  lm(R_moment_1 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model1)

model2 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_2 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)

model3 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_3 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model3)

model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_4 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model4)
```