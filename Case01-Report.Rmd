---
title: "Case Report"
author: "Jack Lichtenstein, Abbey List, Jingxuan Liu, Linda Tang, Mary Wang, and Justin Zhao"
date: "`r Sys.Date()`"
output:
  pdf_document: default
header-includes:
- \usepackage[labelformat = empty]{caption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning=F)
```

```{r load-library}
library(tidyverse)
library(here)
library(splines)
library(broom)
library(knitr)
library(kableExtra)
library(patchwork)
theme_set(theme_light()) # setting a theme
```

```{r load-data}
# remember to set working directory
train <- read.csv("data/data-train.csv")
test <- read.csv("data/data-test.csv")
```

```{r setup-moments}
train <- train %>%
  dplyr::mutate(
    central_1 = R_moment_1, #mean
    central_2 = R_moment_2 - R_moment_1^2, #var
    central_3 = (R_moment_3 - 3*R_moment_2*R_moment_1 + 2*R_moment_1^3), #skew
    central_4 = (R_moment_4 - 4*R_moment_3*R_moment_1 + 6*R_moment_2*R_moment_1^2 - 3*R_moment_1^4)) #kurtosis
```

## 1 Introduction 

Turbulence is a fundamental concept in fluid mechanics. Irregular, unpredictable, and energy-dissipating, turbulent flow enhances mixing, which leads to non-uniform distribution of particles and cluster formation. Understanding and predicting turbulence has great practical significance in many scientific areas including aeronautical engineering and environmental science.

Existing research suggests that the clustering of particles subject toturbulent flow is mainly determined by three main parameters: Reynolds (Re) number, Froude (Fr) number and Stokes (St) number, which correspond to the intentsity of turbulence, impact of gravitational acceleration, and particle properties. These parameters may influence clustering individually; a large $St$, for example, correlates with large particle size, which tends to form relatively loose clusters (Ireland et al., 2016). The parameters may also interact with each other to impact cluser formation.  <!-- insert an example on interaction --> 

Despite the importance of turbulence, current understanding of *how* Re, Fr, and St contribute to clustering remains rudimentary. Similation methods like the Direct Numerical Simulation (DNS) of Navier-Stokes equations have been applied, but progress is limited by the time-consuming and computationally-expensive nature of such methodologies (Moin & Mahesh, 1998). Leveraging on generated data, the present study *aims* to build a statistical model that investigates how Re, Fr and St influence particle cluster volume distribution. We hope that our model will 1) enhance our understanding of the relative influence of these parameters in turbulent flow, and 2) enable a quick and efficient prediction of a particle cluster volume distribution without the needs for simulation.

## 2 Methods

### 2.1 Data

The data (*n* = 89) for the present study comes from Direct Numerical Simulation. Voronoi Tessellation, a technique that examines general features of individual clusters in the underlying turbulence, was applied to generate a distribution of cluster volumes. The original data contains information regarding the generated distributions in the form of the first four raw moments $E(X)$, $E(X^2)$, $E(X^3)$, and $E(X^4)$, as well as Re, Fr, and St values. 

For better interpretability, we transformed the 2nd, 3rd, and 4th raw moments into central moments (Moment 1 is untouched as it already signifies the mean), which describe the variance (how flow varies over time), skewness (indication of symmetric properties of the flow), and kurtosis of the distribution (how particular cluster volumes deviate). In addition, despite their numerical nature, Fr and Re only contains three levels ($Fr \in \{0.052, 0.3, \inf\}$ and $Re \in \{90, 224, 398\}$, see Figure S1 for distribution) in the data. Given such, the variables were converted into factors (See Section 2.4 for an alternative modeling approach that may overcome this limitation). 

### 2.2 Model Building

A closer examination of the data revealed interesting interactive patterns among the independent and dependent variables. Specifically, $St$ appears to assume a strong, non-linear relationship with each of the moments (Figures S1-S4 in the Appendix). These relationships vary between roughly linear to noticeably curved, potentially quadratic or cubic. In addition, such relationships diverge across different moments, and appears highly influenced by the combined levels of $Re$ and $Fr$. From the curved shape of the relationship between `St` and the responses, we also noticed that we may benefit from taking certain roots of `St` to make that more linear. 

Given the paucity of theoretical background in related field to guide model building, we decided to adopt a k-fold validation approach. This approach would allow us to explore different combinations of polynomial patterns and the interactions observed in our EDA and select the best fit model. Specifically, we used K = 5 given the small sample size at hand to avoid overfitting. 

<!-- JL: should we talk about why selecting a linear model? --> 

To implement the k-fold cross validation, for each moment, we trained candidate models to predict the moment with the general formula $Moment_i \sim poly(St_i^{(1/root)} , degree)*(Fr, Re)$, varying the *degree* parameter from 1 to 3, *root* from 1 to 6, and testing a log transformation of the response. We combined $Fr$ and $Re$ to form a new interaction variable $(Fr, Re)$ with 9 levels representing all combinations of $Fr$ and $Re$. We tested the model on each fold, and chose the parameters that give lower root mean squared errors (See Figure 1), with preference for less complexity if the error is similar. After selecting the features for each moment's model, we then fit the final models on the full training dataset using standard least-squares for interpretation. 

<!-- @Jing where to mention diagnostics-->

```{r factors, echo=FALSE}
# make Fr, Re factors
train <- train %>%
  mutate(Fr.numeric = 2/pi*atan(Fr), Re.numeric = Re) %>%
  dplyr::mutate(dplyr::across(c(Fr, Re), factor))
```

```{r cv folds}
# split into train and test
set.seed(123)
train$index <- 1:nrow(train)
spl <- rsample::initial_split(train, prop = 0.8)
tr <- rsample::training(spl)
te <- rsample::testing(spl)
# create folds
set.seed(234)
folds <- rsample::vfold_cv(tr, v = 5)
```

```{r cv lm, echo=FALSE}
# function to train on a given fold, using given degree, predicting given moment
lm_cv <- function(fold, degree, moment, root = 2, log = TRUE) {
  data <- rsample::analysis(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  assess <- rsample::assessment(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  
  data <- data %>%
    dplyr::mutate(St = St^(1/root))
  assess <- assess %>%
    dplyr::mutate(St = St^(1/root))
  
  if (isTRUE(log)) {
    data <- data %>%
      dplyr::mutate(target = log(target))
    assess <- assess
  }
  
  mod <- data %>%
    lm(target ~ poly(St, degree)*interaction, data = .)
  assess <- assess %>%
    dplyr::mutate(pred = predict(mod, ., type = "response") %>% as.numeric())
  
  if (isTRUE(log)) {
    assess <- assess %>%
      dplyr::mutate(pred = exp(pred))
  }
  return(assess)
}
```

```{r cv perform, echo=FALSE}
# compute CV
cv <- tidyr::crossing(fold = 1:5,
                      degree = 1:3,
                      moment = 1:4,
                      root = 1:6,
                      log = c(FALSE)) %>%
  dplyr::mutate(cv = purrr::pmap(list(fold, degree, moment, root, log),
                                 ~ lm_cv(fold = ..1,
                                         degree = ..2,
                                         moment = ..3,
                                         root = ..4,
                                         log = ..5))) %>%
  tidyr::unnest(cv)
```

```{r, echo=FALSE, fig.cap = "\\textbf{Figure 1.} Mean adjusted r-squared value, mean absolute error, and root mean squared error of models for each moment with varying root and polynomial degrees on St. The combination that lead to the lowest root mean squared error was selected as the final model for the moment."}
# transform cv to wide format
cv_wide <- cv %>% 
  dplyr::transmute(index, fold, degree, root, log, 
                   moment = paste0("central_", moment), 
                   pred) %>% 
  tidyr::pivot_wider(names_from = moment,
                     values_from = pred)

# undo central moments
cv_summarized <- cv_wide %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4) %>% 
  # pivot back longer
  tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                      names_to = "moment",
                      values_to = "pred") %>% 
  # join in actual values for each moment
  dplyr::left_join(train %>% 
                     dplyr::select(index, dplyr::starts_with("R_moment_")) %>% 
                     tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                                         names_to = "moment",
                                         values_to = "target"),
                   by = c("index", "moment")) %>% 
  dplyr::group_by(moment = factor(moment), degree, root, log) %>%
  dplyr::summarise(rmse = sqrt(mean((pred-target)^2)),
                   mae = mean(abs(pred-target)),
                   broom::glance(lm(target ~ pred, data = dplyr::cur_data())),
                   .groups = "drop") 

# plot results
cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, mae, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>%
  ggplot(aes(root, value, color = as.factor(degree))) +
  geom_line() +
  geom_point() +
  facet_wrap(~ type, scales = "free", nrow = 4) +
  labs(x = "Root Degree",
       y = NULL,
       color = "Polynomial Degree")
```

### 2.3 Final Models

The final models for each moment, based on the k-fold cross-validation approach, are as below:
$$Raw\:Moment_1 \sim St*(Fr, Re)$$
$$Central\: Moment_2 \sim poly(St^{1/4}, 2) * (Fr, Re)$$
$$Central\: Moment_3 \sim poly(St^{1/3}, 2) * (Fr, Re)$$
$$Central\:Moment_4 \sim poly(\sqrt{St}, 2) * (Fr, Re)$$

### 2.4 Model Extension

As noted above, extrapolating beyond the three levels of $Re$ and three levels of $Fr$ given may be useful for more general predictions and interpretation, since the actual variables have wide domains (@Jing how to word this). To deal with the limitations of our current models, we also provide the following related models that can be used for extrapolation: 

$$R\_moment_1 \sim ns(St, df=1)*Re*Fr'$$
$$R\_moment_2, R\_moment_3, R\_moment_3 \sim ns(\sqrt{St}, df=1)*Re*Fr'$$
In these models, $Re$ is numeric and $Fr$ is transformed to a numeric variable on $[0, 1]$ using $Fr' = \frac{2}{\pi}*arctan(Fr)$. The form is similar in keeping the significant three-way interaction, except with natural splines to address the poor fits of polynomials at the tails, a location that is especially important in learning about particle behavior in high turbulence. Again, the root and degree are chosen through 5-fold cross validation. See appendix for fitted coefficients.

## Results

Selected outputs from the final models of each moment are displayed in Table 1. Please refer to Table S1 for the error values for the final models and Tables S2-S5 for full outputs.

```{r}
# potential outlers: 82 / 80, 85
model1 <- train %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_1 ~ poly(St, 1)*interaction, data = .)
# summary(model1)
#kableExtra::kable(tidy(model1), format = "markdown", digits = 3, 
  #                caption = "Moment 1 Results")
#plot(model1)
```

```{r}
# potential outliers: 20, 65
model2 <- train %>%
  mutate(St = St^(1/4)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_2 ~ poly(St, 2)*interaction, data = .)
#summary(model2)
#kableExtra::kable(tidy(model2), format = "markdown", digits = 3, 
     #             caption = "Moment 2 Results")
#plot(model2)

```

```{r}
# potential outliers: 79, 20
model3 <- train %>%
  mutate(St = St^(1/3)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_3 ~ poly(St, 2)*interaction, data = .)
#summary(model3)
#kableExtra::kable(tidy(model3), format = "markdown", digits = 3, 
       #           caption = "Moment 3 Results")
#plot(model3)
```

```{r Table 1}
#potential outliers: 79
model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_4 ~ poly(St, 2)*interaction, data = .)
#summary(model4)
#kableExtra::kable(tidy(model4), format = "markdown", digits = 3, 
       #           caption = "Moment 4 Results")
#plot(model4)

model1.sig <- tidy(model1) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))


model2.sig <- tidy(model2) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

model3.sig <- tidy(model3) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))

model4.sig <- tidy(model4) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))
```

```{r}
mod.1 <- c("Moment 1", "", "", "", "")
mod.2 <- c("Moment 2", "", "", "", "")
mod.3 <- c("Moment 3", "", "", "", "")
mod.4 <- c("Moment 4", "", "", "", "")
Table_combined <- as.data.frame(rbind(mod.1, model1.sig, mod.2, model2.sig, mod.3, model3.sig, mod.4, model4.sig))

Table_combined[1,1] <- cell_spec(Table_combined[1,1], bold = T)
Table_combined[8,1] <- cell_spec(Table_combined[8,1], bold = T)
Table_combined[12,1] <- cell_spec(Table_combined[12,1], bold = T)
Table_combined[16,1] <- cell_spec(Table_combined[16,1], bold = T)

 kable(Table_combined, format = "latex", 
        escape = F, booktabs = T, longtable=T, linesep = NULL,
        col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        )) %>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Outputs from final models of each moment. Only the significant terms are displayed here given limited space. Please refer to Tables XX-XX in Appendix for full output.",
           general_title = "Table 1.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```


```{r predict on holdout}
test <- test %>% 
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)

# central 1
test$central_1 = test %>% 
  predict(model1, ., type = "response")
# central 2
test$central_2 = test %>%
  mutate(St = St^(1/4)) %>%
  predict(model2, ., type = "response")
# central 3
test$central_3 = test %>%
  mutate(St = St^(1/3)) %>%
  predict(model3, ., type = "response")
# central 4
test$central_4 = test %>%
  mutate(St = sqrt(St)) %>%
  predict(model4, ., type = "response")

test <- test %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4)

# write.csv(test, file="data/data-test_pred.csv")
```

## Discussion

Broadly speaking, a Reynolds number > 4000 generally represents a relatively chaotic and turbulent flow, a Reynolds number < 2300 generally represents a smooth laminar flow and any number in between typically represents transient flow (Schlichting et al., 2017).

However, large Reynolds numbers is highly relevant to real life situations (atmospheric, oceanic turbulence flow).

The Reynolds number is a measure of the intensity of turbulence, with a higher Reynolds number corresponding to a higher intensity of turbulence (J. den Toonder et al., 1997). The Froude number is a measure of the impact of gravitational acceleration on fluid motion;  

For instance, a cumulonimbus cloud at a high level above the ground will have a smaller Froude number (compared to lower hanging stratus clouds) because it experiences a lower intensity of gravitational acceleration relative to other clouds (Chanson, 2009). Stokes number is a description of particle properties; a large Stokes number correlates with large particle size which tends to form relatively loose clusters (Ireland et al., 2016). 

but it is extremely time consuming and computationally expensive . In addition, the DNS method cannot be practically applied to simulate flows with large Reynolds numbers which requires high resolution, leading to long computation time. 

Since this probability distribution of cluster volumes is harder for statistical learning methods to work with, we will summarize this distribution by its first four raw moments $E(X)$, $E(X^2)$, $E(X^3)$, and $E(X^4)$, the latter three which we transform to central moments as response variables for inference and back for prediction. Theoretically, we are interested in the insights for each of these four moments - the mean of the distribution could be a good indicator of how flow behaves on average, the variance of the distribution could dictate how flow varies over time, the skew of the distribution could illustrate asymmetric properties of the flow, and the kurtosis of the distribution could indicate how particular cluster volumes deviate.

For $Fr$ in particular, 0.3 represents cumulonimbus clouds and 0.052 represents cumulus clouds.

\newpage

## References

- J. M. J.  den Toonder, &amp; Nieuwstadt, F. T. M. (1997, November 1). Reynolds number effects in a turbulent pipe flow for low to moderate re. AIP Publishing. Retrieved October 12, 2021, from https://aip.scitation.org/doi/pdf/10.1063/1.869451. 

- Schlichting, H., Gersten, K., Krause, E., &amp; Oertel, H. (2017). Boundary-layer theory. Springer. 

- Chanson, Hubert (2009). "Development of the Bélanger Equation and Backwater Equation by Jean-Baptiste Bélanger (1828)" (PDF). Journal of Hydraulic Engineering. 135 (3): 159–63. doi:10.1061/(ASCE)0733-9429(2009)135:3(159).

- Ireland, P. J., Bragg, A. D., &amp; Collins, L. R. (2016, May 11). The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. part&nbsp;2. simulations with gravitational effects: Journal of Fluid Mechanics. Cambridge Core. Retrieved October 12, 2021, from https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/effect-of-reynolds-number-on-inertial-particle-dynamics-in-isotropic-turbulence-part-2-simulations-with-gravitational-effects/67C55CDC28B1B1C7868B7A402E279AF9. 

- Moin, P., &amp; Mahesh, K. (n.d.). Direct numerical simulation: A tool in turbulence research. Annual Reviews. Retrieved October 12, 2021, from https://www.annualreviews.org/doi/full/10.1146/annurev.fluid.30.1.539. 

- slides: https://sakai.duke.edu/access/content/group/e1e1b166-17bd-4efc-bdfb-f3909d696910/Case%20Study/Data_Expedition_F2020_Reza_Jon.pdf

\newpage

## Appendix 

### Figures 

```{r fig-S1, fig.height = 3, fig.width=8, fig.cap="\\textbf{Figure S1.} Distribution of the three levels of Re and Fr. The values are treated as factor levels in our main analysis."}
# histograms of predictors
tr %>%
  pivot_longer(cols = c(Re:Fr),
               names_to = "metric",
               values_to = "value") %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 20, stat="count") +
  facet_wrap(~ metric, scales = "free")
```

```{r Figure-S2, fig.height = 3.5, fig.cap = "\\textbf{Figure S2.} Moment 1 values as a function of St at different levels of interaction between Fr and Re."}
tr %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Moment 1", color = "Fr:Re")
```

```{r Figure-S3, fig.height = 3.5, fig.cap = "\\textbf{Figure S3.} Central Moment 2 values as a function of St at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_2, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 2", color = "Fr:Re")
```

```{r Figure-S4, fig.height = 3.5, fig.cap = "\\textbf{Figure S4.} Central Moment 3 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_3, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 3", color = "Fr:Re")
```

```{r Figure-S5, fig.height = 3.5, fig.cap = "\\textbf{Figure S5.} Central Moment 4 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_4, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 4", color = "Fr:Re")
```

\newpage 

### Model Diagnoistics

**Modeling assumptions for linear regression**: 

1. **Linearity**: Linearity is satisfied for all 4 models since in the residuals vs. predicted plot, there's no obvious pattern in the residuals are the value of the predictors increase. The residuals are randomly scattered around 0, supporting that there's a linear relationship between the predictors and the response (after variable transformation). 
2. **Constant variance**: In the residuals vs. predicted plot for all 4 models, the vertical spread of the residual remain relatively constant as the predicted values increases, suggesting that the variance of the error is constant along all predicted values. 
3. **Independence**: The data was generated from Direct Numerical Stimulation (DNS) of the Navier-Stokes equations, where each trial was conducted independently using different values of the parameter (Re, Fr, St). Based on the information about data collection, we believe the independence assumption is satisfied.
4. **Normality**: Normality may be violated since the distribution of the residuals doesn't follow a normal distribution and the points do not fall along a straight diagonal line on the normal quantile plot. The flat region in the normal quantile plot indicates there's a lot of nearly identical values, and the curved shape suggests that the distribution may be heavy-tailed. This violation makes sense in the context of the dataset since we observed that both the raw moments and central moments are highly skewed to the right with most values close to 0 with some extreme outliers. 

**Influential points and outliers**: We assessed outliers and influential points in our dataset using Cook's distance 

```{r diag}
diag_plot <- function(model) {
  
  resid_fitted <- ggplot(data = model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Predicted values", 
       y = "Residual", 
       title = "Residuals vs. Predicted") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6))

  resid_qq <- ggplot(data = model, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() +
  labs(title = "Normal QQ-plot of residuals") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6))
  
  model_aug <- augment(model) %>%
    mutate(obs_num = row_number()) 

  cook <- ggplot(data = model_aug, aes(x = obs_num, y = .cooksd)) + 
    geom_point(alpha = 0.7) + 
    geom_hline(yintercept = 0.5, color = "blue", lty = 2) +
    geom_hline(yintercept = 1, color = "red", lty = 3) +
    labs(x = "Observation Number", y = "Cook's distance") +
    geom_text(aes(label = ifelse(.hat > 1,
                               as.character(obs_num), "")), nudge_x = 4) + 
    labs(title = "Observation number vs. Cook's distance") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6))
  
  resid_fitted / (resid_qq + cook) + 
    plot_annotation(tag_levels = 'A') & theme(plot.tag = element_text(size = 8))
}
```

```{r Diag Model 1, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 1."}
#model1 <- augment(model1)
diag_plot(model1)
```

```{r Diag Model 2, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 2."}
diag_plot(model2)
```

```{r Diag Model 3, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 3."}
diag_plot(model3)
```

```{r Diag Model 4, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 4."}
diag_plot(model4)
```

\newpage

### Tables 

```{r table-s1 cv results, echo=FALSE}
tableS1 <-cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, mae, adj.r.squared)) %>% 
  dplyr::group_by(moment, name) %>% 
  dplyr::mutate(best = ifelse(name == "adj.r.squared", max(value), min(value))) %>% 
  ungroup() %>% 
  filter(value == best) %>% 
  select(moment, degree, root, log, name, value) %>% 
  mutate(value = scales::comma(value, accuracy = 0.00001)) 

kable(tableS1, booktabs = T)%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Errors from final models for each moment",
           general_title = "Table S1.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s2}
mod1 <- tidy(model1) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  ))
kable(mod1, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Moment One",
           general_title = "Table S2.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)

```

```{r table-s3}
mod2 <- tidy(model2) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 

kable(mod2, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Two",
           general_title = "Table S3.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s4}
mod3 <- tidy(model3) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 

kable(mod3, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Three",
           general_title = "Table S4.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s5}
mod4 <- tidy(model4) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 

kable(mod4, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Five",
           general_title = "Table S5.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```


```{r eval = FALSE}
# Note: don't perform as well because splines tend to require more data to fit + extrapolation means more uncertainty generally
model1 <- train %>%
  lm(R_moment_1 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model1)

model2 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_2 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)

model3 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_3 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model3)

model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_4 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model4)
```

```{r}
train %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_2, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_3, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_4, color = interaction(Re,Fr))) +
  geom_point()
```
