---
title: "Case Report"
author: "Jack Lichtenstein, Abbey List, Jingxuan Liu, Linda Tang, Mary Wang, and Justin Zhao"
output:
  pdf_document: default
header-includes:
- \usepackage[labelformat = empty]{caption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning=F)
```

```{r load-library}
library(tidyverse)
library(here)
library(splines)
library(broom)
library(knitr)
library(kableExtra)
library(patchwork)
library(car)
theme_set(theme_light()) # setting a theme
```

```{r load-data}
# remember to set working directory
train <- read.csv("data/data-train.csv")
test <- read.csv("data/data-test.csv")
```

```{r setup-moments}
train <- train %>%
  dplyr::mutate(
    central_1 = R_moment_1, #mean
    central_2 = R_moment_2 - R_moment_1^2, #var
    central_3 = (R_moment_3 - 3*R_moment_2*R_moment_1 + 2*R_moment_1^3), #skew
    central_4 = (R_moment_4 - 4*R_moment_3*R_moment_1 + 6*R_moment_2*R_moment_1^2 - 3*R_moment_1^4)) #kurtosis
```

## 1 Introduction 

Turbulence is a fundamental concept in fluid mechanics. Irregular, unpredictable, and energy-dissipating, turbulent flow enhances mixing, which leads to non-uniform distribution of particles and cluster formation. Understanding and predicting turbulence has great practical significance in many scientific areas including aeronautical engineering and environmental science.

Existing research suggests that the clustering of particles subject toturbulent flow is mainly determined by three main parameters: Reynolds (Re) number, Froude (Fr) number and Stokes (St) number, which correspond to the intentsity of turbulence, impact of gravitational acceleration, and particle properties (Chanson, 2009; Ireland et al., 2016). These parameters may influence clustering individually; a large $St$, for example, correlates with large particle size, which tends to form relatively loose clusters (Ireland et al., 2016). The parameters may also interact with each other to impact cluser formation.  <!-- insert an example on interaction --> 

Despite the importance of turbulence, current understanding of *how* Re, Fr, and St contribute to clustering remains rudimentary. Similation methods like the Direct Numerical Simulation (DNS) of Navier-Stokes equations have been applied, but progress is limited by the time-consuming and computationally-expensive nature of such methodologies (Moin & Mahesh, 1998). Leveraging on generated data, the present study *aims* to build a statistical model that investigates how Re, Fr and St influence particle cluster volume distribution. We hope that our model will 1) enhance our understanding of the relative influence of these parameters in turbulent flow, and 2) enable a quick and efficient prediction of a particle cluster volume distribution without the needs for simulation.

## 2 Methods

### 2.1 Data

The data (*n* = 89) for the present study comes from Direct Numerical Simulation. Voronoi Tessellation, a technique that examines general features of individual clusters in the underlying turbulence, was applied to generate a distribution of cluster volumes. The original data contains information regarding the generated distributions in the form of the first four raw moments $E(X)$, $E(X^2)$, $E(X^3)$, and $E(X^4)$, as well as Re, Fr, and St values. 

For better interpretability, we transformed the 2nd, 3rd, and 4th raw moments into central moments (Moment 1 is untouched as it already signifies the mean), which describe the variance (how flow varies over time), skewness (indication of symmetric properties of the flow), and kurtosis of the distribution (how particular cluster volumes deviate). In addition, despite their numerical nature, Fr and Re only contains three levels ($Fr \in \{0.052, 0.3, \inf\}$ and $Re \in \{90, 224, 398\}$, see Figure S1 for distribution) in the data. Given such, the variables were converted into factors (See Section 2.4 for an alternative modeling approach that may overcome this limitation). 

### 2.2 Model Building

A closer examination of the data revealed interesting interactive patterns among the independent and dependent variables. Specifically, $St$ appears to assume a strong, non-linear relationship with each of the moments (Figures S1-S4 in the Appendix). These relationships vary between roughly linear to noticeably curved, potentially quadratic or cubic. In addition, such relationships diverge across different moments, and appears highly influenced by the combined levels of $Re$ and $Fr$. From the curved shape of the relationship between `St` and the responses, we also noticed that we may benefit from taking certain roots of `St` to make that more linear. 

Given the paucity of theoretical background in related field to guide model building, we decided to adopt a k-fold validation approach. This approach would allow us to explore different combinations of polynomial patterns and the interactions observed in our EDA and select the best fit model. Specifically, we used K = 5 given the small sample size at hand to avoid overfitting. 

<!-- JL: should we talk about why selecting a linear model? --> 

To implement the k-fold cross validation, for each moment, we trained candidate models to predict the moment with the general formula $Moment_i \sim poly(St_i^{(1/root)} , degree)*(Fr, Re)$, varying the *degree* parameter from 1 to 3, *root* from 1 to 6, and testing a log transformation of the response. We combined $Fr$ and $Re$ to form a new interaction variable $(Fr, Re)$ with 9 levels representing all combinations of $Fr$ and $Re$. We tested the model on each fold, and chose the parameters that give lower root mean squared errors (See Figure 1), with preference for less complexity if the error is similar. After selecting the features for each moment's model, we then fit the final models on the full training dataset using standard least-squares for interpretation. 

<!-- @Jing where to mention diagnostics-->

```{r factors, echo=FALSE}
# make Fr, Re factors
train <- train %>%
  mutate(Fr.numeric = 2/pi*atan(Fr), Re.numeric = Re) %>%
  dplyr::mutate(dplyr::across(c(Fr, Re), factor))
```

```{r cv folds}
# split into train and test
set.seed(123)
train$index <- 1:nrow(train)
spl <- rsample::initial_split(train, prop = 0.8)
tr <- rsample::training(spl)
te <- rsample::testing(spl)
# create folds
set.seed(234)
folds <- rsample::vfold_cv(tr, v = 5)
```

```{r cv lm, echo=FALSE}
# function to train on a given fold, using given degree, predicting given moment
lm_cv <- function(fold, degree, moment, root = 2, log = TRUE) {
  data <- rsample::analysis(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  assess <- rsample::assessment(folds$splits[[fold]]) %>%
    dplyr::mutate(target = !!dplyr::sym(paste0("central_", moment))) %>% 
    tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
  
  data <- data %>%
    dplyr::mutate(St = St^(1/root))
  assess <- assess %>%
    dplyr::mutate(St = St^(1/root))
  
  if (isTRUE(log)) {
    data <- data %>%
      dplyr::mutate(target = log(target))
    assess <- assess
  }
  
  mod <- data %>%
    lm(target ~ poly(St, degree)*interaction, data = .)
  assess <- assess %>%
    dplyr::mutate(pred = predict(mod, ., type = "response") %>% as.numeric())
  
  if (isTRUE(log)) {
    assess <- assess %>%
      dplyr::mutate(pred = exp(pred))
  }
  return(assess)
}
```

```{r cv perform, echo=FALSE}
# compute CV
cv <- tidyr::crossing(fold = 1:5,
                      degree = 1:3,
                      moment = 1:4,
                      root = 1:6,
                      log = c(FALSE)) %>%
  dplyr::mutate(cv = purrr::pmap(list(fold, degree, moment, root, log),
                                 ~ lm_cv(fold = ..1,
                                         degree = ..2,
                                         moment = ..3,
                                         root = ..4,
                                         log = ..5))) %>%
  tidyr::unnest(cv)
```

```{r, fig.height = 3, echo=FALSE, fig.cap = "\\textbf{Figure 1.} Mean adjusted r-squared value, mean absolute error, and root mean squared error of models for each moment with varying root and polynomial degrees on St. The combination that lead to the lowest root mean squared error was selected as the final model for the moment."}

# transform cv to wide format
cv_wide <- cv %>% 
  dplyr::transmute(index, fold, degree, root, log, 
                   moment = paste0("central_", moment), 
                   pred) %>% 
  tidyr::pivot_wider(names_from = moment,
                     values_from = pred)
# undo central moments
cv_summarized <- cv_wide %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4) %>% 
  # pivot back longer
  tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                      names_to = "moment",
                      values_to = "pred") %>% 
  # join in actual values for each moment
  dplyr::left_join(train %>% 
                     dplyr::select(index, dplyr::starts_with("R_moment_")) %>% 
                     tidyr::pivot_longer(cols = dplyr::starts_with("R_moment_"),
                                         names_to = "moment",
                                         values_to = "target"),
                   by = c("index", "moment")) %>% 
  dplyr::group_by(moment = factor(moment), degree, root, log) %>%
  dplyr::summarise(rmse = sqrt(mean((pred-target)^2)),
                   broom::glance(lm(target ~ pred, data = dplyr::cur_data())),
                   .groups = "drop") 
# plot results
ar2 <- cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>% 
  filter(name == "adj.r.squared")

rmse <- cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>%
  tidyr::unite(type, moment, name, sep = ": ", remove = FALSE) %>% 
  filter(name == "rmse")

p1 <- ggplot(data = rmse, aes(root, value, color = as.factor(degree))) +
  geom_line(legend = F) +
  geom_point(show.legned = F) +
  facet_wrap(~ type, scales = "free", ncol = 4) +
  labs(x = "Root Degree",
       y = NULL,
       color = "Polynomial Degree") + 
  theme(legend.title = element_text(size = 5), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))

p2 <- ggplot(data = ar2, aes(root, value, color = as.factor(degree))) +
  geom_line(legend = F) +
  geom_point(show.legned = F) +
  facet_wrap(~ type, scales = "free", ncol = 4) +
  labs(x = "Root Degree",
       y = NULL,
       color = "Polynomial Degree") + 
  theme(legend.title = element_text(size = 5), 
        legend.text = element_text(size = 5), 
        axis.title = element_text(size = 6),
        axis.text = element_text(size = 5), 
        strip.text.x = element_text(size = 5))

p1 / p2 + plot_layout(guides = 'collect')
```

### 2.3 Final Models

The final models for each moment, based on the k-fold cross-validation approach, are as below:
$$Raw\:Moment_1 \sim St*(Fr, Re)$$
$$Central\: Moment_2 \sim poly(St^{1/4}, 2) * (Fr, Re)$$
$$Central\: Moment_3 \sim poly(St^{1/3}, 2) * (Fr, Re)$$
$$Central\:Moment_4 \sim poly(\sqrt{St}, 2) * (Fr, Re)$$

The linearity, constant variance, independence assumption for linear regression is satisfied and we observed some violation of normality. There's few outliers and influential points. Furthermore, the variance inflation factors indicate no serious concerns of multicolinearity (Model diagnoistics section in the Appendix). 

### 2.4 Model Extension

As noted above, extrapolating beyond the three levels of $Re$ and three levels of $Fr$ given may be useful for more general predictions and interpretation, since the actual variables have wide domains (@Jing how to word this). To deal with the limitations of our current models, we also provide the following related models that can be used for extrapolation: 

$$R\_moment_1 \sim ns(St, df=1)*Re*Fr'$$
$$R\_moment_2, R\_moment_3, R\_moment_3 \sim ns(\sqrt{St}, df=1)*Re*Fr'$$
In these models, $Re$ is numeric and $Fr$ is transformed to a numeric variable on $[0, 1]$ using $Fr' = \frac{2}{\pi}*arctan(Fr)$. The form is similar in keeping the significant three-way interaction, except with natural splines to address the poor fits of polynomials at the tails, a location that is especially important in learning about particle behavior in high turbulence. Again, the root and degree are chosen through 5-fold cross validation. See appendix for fitted coefficients.

## Results

Selected outputs from the final models of each moment are displayed in Table 1. Please refer to Table S1 for the error values for the final models and Tables S2-S5 for full outputs.

```{r}
# potential outlers: 82 / 80, 85
model1 <- train %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_1 ~ poly(St, 1)*interaction, data = .)
# summary(model1)
#kableExtra::kable(tidy(model1), format = "markdown", digits = 3, 
  #                caption = "Moment 1 Results")
#plot(model1)
```

```{r}
# potential outliers: 20, 65
model2 <- train %>%
  mutate(St = St^(1/4)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_2 ~ poly(St, 2)*interaction, data = .)
#summary(model2)
#kableExtra::kable(tidy(model2), format = "markdown", digits = 3, 
     #             caption = "Moment 2 Results")
#plot(model2)
```

```{r}
# potential outliers: 79, 20
model3 <- train %>%
  mutate(St = St^(1/3)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_3 ~ poly(St, 2)*interaction, data = .)
#summary(model3)
#kableExtra::kable(tidy(model3), format = "markdown", digits = 3, 
       #           caption = "Moment 3 Results")
#plot(model3)
```

```{r Table 1}
#potential outliers: 79
model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE) %>%
  lm(central_4 ~ poly(St, 2)*interaction, data = .)
#summary(model4)
#kableExtra::kable(tidy(model4), format = "markdown", digits = 3, 
       #           caption = "Moment 4 Results")
#plot(model4)
model1.sig <- tidy(model1) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))
model2.sig <- tidy(model2) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))
model3.sig <- tidy(model3) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))
model4.sig <- tidy(model4) %>%
  filter(p.value < 0.05) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3))) %>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    TRUE ~ as.character(p.value)
  ))
```

```{r}
mod.1 <- c("Moment 1", "", "", "", "")
mod.2 <- c("Moment 2", "", "", "", "")
mod.3 <- c("Moment 3", "", "", "", "")
mod.4 <- c("Moment 4", "", "", "", "")
Table_combined <- as.data.frame(rbind(mod.1, model1.sig, mod.2, model2.sig, mod.3, model3.sig, mod.4, model4.sig))
Table_combined[1,1] <- cell_spec(Table_combined[1,1], bold = T)
Table_combined[8,1] <- cell_spec(Table_combined[8,1], bold = T)
Table_combined[12,1] <- cell_spec(Table_combined[12,1], bold = T)
Table_combined[16,1] <- cell_spec(Table_combined[16,1], bold = T)
 kable(Table_combined, format = "latex", 
        escape = F, booktabs = T, longtable=T, linesep = NULL,
        col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        )) %>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Outputs from final models of each moment. Only the significant terms are displayed here given limited space. Please refer to Tables XX-XX in Appendix for full output.",
           general_title = "Table 1.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```


```{r predict on holdout}
test <- test %>% 
  tidyr::unite(interaction, Fr, Re, sep = ": ", remove = FALSE)
# central 1
test$central_1 = test %>% 
  predict(model1, ., type = "response")
# central 2
test$central_2 = test %>%
  mutate(St = St^(1/4)) %>%
  predict(model2, ., type = "response")
# central 3
test$central_3 = test %>%
  mutate(St = St^(1/3)) %>%
  predict(model3, ., type = "response")
# central 4
test$central_4 = test %>%
  mutate(St = sqrt(St)) %>%
  predict(model4, ., type = "response")
test <- test %>% 
  dplyr::mutate(R_moment_1 = central_1,
                R_moment_2 = central_2 + R_moment_1^2,
                R_moment_3 = central_3 + 3*R_moment_2*R_moment_1 - 2*R_moment_1^3,
                R_moment_4 = central_4 + 4*R_moment_3*R_moment_1 - 6*R_moment_2*R_moment_1^2 + 3*R_moment_1^4)
# write.csv(test, file="data/data-test_pred.csv")
```

From Table S1 in the Appendix, we can observe that all models possess an adjusted $R^2$ of at least 0.98, indicating that at least 98% of the variation in each centralized moment is explained by the predictors in the models. The test error (modeled by root mean squared error) is only 0.00764 and 20.86 for models of centralized moments 1 and 2, respectively. It is larger for models of centralized moments 3 and 4 (above 200,000 and above 1 million, respectively), but this is expected given the extremely large values in these moments.  

For centralized moment 1, we see that interactions between all settings of Fr and the lowest setting of Re, along with their interactions with St, yield an expected increase in mean particle cluster volume size. This indicates that smoother flow at any level of gravitational acceleration and particle size may allow larger clusters to form, as they are not broken up by chaotic turbulence. These coefficients are statistically significant at the $\alpha = 0.01$ level with small standard errors.  

For centralized moments 2, 3, and 4, it appears that the interaction between lowest Fr and lowest Re, along with its interaction with St, has a positive association with each moment. The interaction with squared St has a negative association with each moment (note that the exact value of this squared transformation differs based on the root transformation applied to St for each moment) (?????? ask simon about interpreting positive non-squared, negative squared). This indicates that smoother flow and low gravitational acceleration are associated with greater variance, skew, and kurtosis (distributional "tailedness") of particle cluster size. The effect of particle size at these levels of Re and Fr may differ from the effect at other levels, as it is only statistically significant at these low settings of flow intensity and gravitational acceleration. These coefficients are statistically significant at the $\alpha = 0.01$ level.  

## Discussion

In this study, we have utilized four linear models with polynomial terms and interaction terms between Reynolds' number, Froude's number, and Stokes' number to predict the first four centralized moments (mean, variance, skew, and kurtosis) of particle cluster distribution. These variables explained a large percentage of variation in each of the four moments, with reasonable mean squared error for each model. We found that smoother flow at any level of gravitational acceleration and particle size may be associated with larger mean cluster size, and smoother flow with low gravitational acceleration seemed to have a positive association with variance, skew, and kurtosis. Also, the effects of particle size on each moment seemed to be significantly different at lower flow intensity and lower gravitational acceleration than at other settings. Finally, it appears that for centralized moments 2, 3, and 4, the main effect of St (at low Fr and Re) has a positive association with the moments, while the squared effect has a negative association (how to explain this ?). 

One limitation of our analysis is that Fr and Re are categorical variables in our models, while they are truly numeric. This may have a negative effect on predictive performance for extrapolation on values outside our categories; however, Section 2.4 describes a numerical model that can be used for extrapolation (did we ever provide the results for that model?).  

Also, our model was fit on Reynolds numbers up to 398, although numbers in the thousands are common in practice. Large Reynolds numbers are highly relevant to real life situations as a measure of turbulence intensity in atmospheric, oceanic turbulence flow (J. den Toonder et al., 1997), and although our modeling approach avoids the high computational cost of simulation at large Reynolds numbers, it may not be suitable for extrapolation at these settings due to the small numbers in the dataset. Using numerical variables and higher Reynolds numbers may be topics for further investigation.  

In summary, we hope these results can be used towards both predicting the distribution of particle cluster size as well as understanding the effects of Reynolds, Froude, and Stokes numbers on particle cluster size.

\newpage

## References

- J. M. J.  den Toonder, &amp; Nieuwstadt, F. T. M. (1997, November 1). Reynolds number effects in a turbulent pipe flow for low to moderate re. AIP Publishing. Retrieved October 12, 2021, from https://aip.scitation.org/doi/pdf/10.1063/1.869451. 

- Schlichting, H., Gersten, K., Krause, E., &amp; Oertel, H. (2017). Boundary-layer theory. Springer. 

- Chanson, Hubert (2009). "Development of the Bélanger Equation and Backwater Equation by Jean-Baptiste Bélanger (1828)" (PDF). Journal of Hydraulic Engineering. 135 (3): 159–63. doi:10.1061/(ASCE)0733-9429(2009)135:3(159).

- Ireland, P. J., Bragg, A. D., &amp; Collins, L. R. (2016, May 11). The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. part&nbsp;2. simulations with gravitational effects: Journal of Fluid Mechanics. Cambridge Core. Retrieved October 12, 2021, from https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/effect-of-reynolds-number-on-inertial-particle-dynamics-in-isotropic-turbulence-part-2-simulations-with-gravitational-effects/67C55CDC28B1B1C7868B7A402E279AF9. 

- Moin, P., &amp; Mahesh, K. (n.d.). Direct numerical simulation: A tool in turbulence research. Annual Reviews. Retrieved October 12, 2021, from https://www.annualreviews.org/doi/full/10.1146/annurev.fluid.30.1.539. 

- slides: https://sakai.duke.edu/access/content/group/e1e1b166-17bd-4efc-bdfb-f3909d696910/Case%20Study/Data_Expedition_F2020_Reza_Jon.pdf

\newpage

## Appendix 

### Figures 

```{r fig-S1, fig.height = 3, fig.width=8, fig.cap="\\textbf{Figure S1.} Distribution of the three levels of Re and Fr. The values are treated as factor levels in our main analysis."}
# histograms of predictors
tr %>%
  pivot_longer(cols = c(Re:Fr),
               names_to = "metric",
               values_to = "value") %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 20, stat="count") +
  facet_wrap(~ metric, scales = "free")
```

```{r Figure-S2, fig.height = 3.5, fig.cap = "\\textbf{Figure S2.} Moment 1 values as a function of St at different levels of interaction between Fr and Re."}
tr %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Moment 1", color = "Fr:Re")
```

```{r Figure-S3, fig.height = 3.5, fig.cap = "\\textbf{Figure S3.} Central Moment 2 values as a function of St at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_2, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 2", color = "Fr:Re")
```

```{r Figure-S4, fig.height = 3.5, fig.cap = "\\textbf{Figure S4.} Central Moment 3 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = central_3, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 3", color = "Fr:Re")
```

```{r Figure-S5, fig.height = 3.5, fig.cap = "\\textbf{Figure S5.} Central Moment 4 values as a function of particle size at different levels of interaction between Fr and Re."}
train %>%
  ggplot(aes(x = St, y = R_moment_4, color = interaction(Fr, Re))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ interaction(Fr, Re), scales = "free") +
  labs(x = "St", y = "Central Moment 4", color = "Fr:Re")
```

\newpage 

### Model Diagnoistics

***Modeling assumptions for linear regression***: 

* **Linearity**: Linearity is satisfied for all 4 models since in the predicted vs. standardized residuals plots (Panel A), there's no obvious pattern in the residuals are the value of the predictors increase. The residuals are randomly scattered around 0, supporting that there's a linear relationship between the predictors and the response (after variable transformation). 
* **Constant variance**: In the residuals vs. predicted plot for all 4 models, the vertical spread of the residual remain relatively constant as the predicted values increases, suggesting that the variance of the error is constant along all predicted values (Panel A). 
* **Independence**: The data was generated from Direct Numerical Stimulation (DNS) of the Navier-Stokes equations, where each trial was conducted independently using different values of the parameter (Re, Fr, St). Based on the information about data collection, we believe the independence assumption is satisfied.
* **Normality**: Normality may be violated since the distribution of the residuals doesn't follow a normal distribution and the points do not fall along a straight diagonal line on the normal quantile plot. The flat region in the normal quantile plot indicates there's a lot of nearly identical values, and the curved shape suggests that the distribution may be heavy-tailed. This violation makes sense in the context of the dataset since we observed that both the raw moments and central moments are highly skewed to the right with most values close to 0 with some extreme outliers (Panel B). 

***Influential points and outliers***: We assessed influential points in our dataset using Cook's distance (Panel C). Besides having a few influential points for model 1, all observations had Cook's distance less than 0.5 for the rest of the models. In addition, from the predicted vs. standardized residuals plots (Panel A), there are only a few outliers with standardized residual greater than 5.

***Multicolinearity***: We assessed multicolinearity using variance inflation factor (VIF), which was below 10 for all predictors in all 4 models, suggesting no serious issue of multicolinearity. 

```{r diag}
diag_plot <- function(model) {
  
  model_aug <- augment(model) %>%
    mutate(obs_num = row_number())

  resid_fitted <- ggplot(data = model_aug, aes(x = .fitted, y = .std.resid)) +
    geom_point(alpha = 0.7) +
    geom_hline(yintercept = c(-2, 2), color = "blue", lty = 2) +
    geom_hline(yintercept = c(-3, 3), color = "red", lty = 3) +
    labs(x = "Predicted values",
         y = "Standardized Residual",
         title = "Fitted vs. Standardized Residual") +
    theme_bw() +
    theme(plot.title = element_text(size = 8),
          axis.title = element_text(size = 6),
          axis.text = element_text(size = 5))

  resid_qq <- ggplot(data = model, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() +
  labs(title = "Normal Quantile plot of residuals") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6), 
          axis.text = element_text(size = 5))
  
  cook <- ggplot(data = model_aug, aes(x = obs_num, y = .cooksd)) + 
    geom_point(alpha = 0.7) + 
    geom_hline(yintercept = 0.5, color = "blue", lty = 2) +
    geom_hline(yintercept = 1, color = "red", lty = 3) +
    labs(x = "Observation Number", y = "Cook's distance") +
    geom_text(aes(label = ifelse(.hat > 1,
                               as.character(obs_num), "")), nudge_x = 4) + 
    labs(title = "Observation number vs. Cook's distance") + 
    theme(plot.title = element_text(size = 8), 
          axis.title = element_text(size = 6), 
          axis.text = element_text(size = 5))
  
  resid_fitted / (resid_qq + cook) + 
    plot_annotation(tag_levels = 'A') & theme(plot.tag = element_text(size = 8))
}
```

```{r Diag Model 1, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 1."}
diag_plot(model1)
```

```{r}
vif(model1) %>% kable(format = "markdown")
```

```{r Diag Model 2, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 2."}
diag_plot(model2)
```

```{r}
vif(model2) %>% kable(format = "markdown")
```

```{r Diag Model 3, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 3."}
diag_plot(model3)
```

```{r}
vif(model3) %>% kable(format = "markdown")
```

```{r Diag Model 4, fig.height = 5, fig.cap = "\\textbf{Figure S?.} Diagnoistic plots for Model 4."}
diag_plot(model4)
```

```{r}
vif(model4) %>% kable(format = "markdown")
``` 

\newpage

### Tables 

```{r table-s1 cv results, echo=FALSE}
tableS1 <-cv_summarized %>% 
  tidyr::pivot_longer(cols = c(rmse, adj.r.squared)) %>% 
  dplyr::group_by(moment, name) %>% 
  dplyr::mutate(best = ifelse(name == "adj.r.squared", max(value), min(value))) %>% 
  ungroup() %>% 
  filter(value == best) %>% 
  select(moment, degree, root, log, name, value) %>% 
  mutate(value = scales::comma(value, accuracy = 0.00001)) 
kable(tableS1, booktabs = T)%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Errors from final models for each moment",
           general_title = "Table S1.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s2}
mod1 <- tidy(model1) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  ))
kable(mod1, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Moment One",
           general_title = "Table S2.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s3}
mod2 <- tidy(model2) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 
kable(mod2, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Two",
           general_title = "Table S3.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s4}
mod3 <- tidy(model3) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 
kable(mod3, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Three",
           general_title = "Table S4.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```

```{r table-s5}
mod4 <- tidy(model4) %>%
  mutate(across(where(is.numeric), ~ round(.x, digits = 3)))%>%
  mutate(p.value = case_when(
    p.value < 0.001 ~ "<0.001",
    p.value > 0.999 ~ ">0.999",
    TRUE ~ as.character(p.value)
  )) 
kable(mod4, booktabs = T, escape = F, linesep = NULL, col.names = c(
          "Term", "$\\beta$", "$SE$", "$t$", "$p$ value"
        ))%>% 
  kable_styling(position = "center")  %>% 
  footnote(general = "Full output of the final model for predicting Central Moment Five",
           general_title = "Table S5.",
           footnote_as_chunk = TRUE,
           title_format = "bold",
           escape = FALSE,
           threeparttable = TRUE)
```


```{r eval = FALSE}
# Note: don't perform as well because splines tend to require more data to fit + extrapolation means more uncertainty generally
model1 <- train %>%
  lm(R_moment_1 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model1)
model2 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_2 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
model3 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_3 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model3)
model4 <- train %>%
  mutate(St = sqrt(St)) %>%
  lm(R_moment_4 ~ ns(St, df=1)*Re.numeric*Fr.numeric, data= .)
summary(model4)
```

```{r}
train %>%
  ggplot(aes(x = St, y = R_moment_1, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_2, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_3, color = interaction(Re,Fr))) +
  geom_point()
train %>%
  ggplot(aes(x = St, y = central_4, color = interaction(Re,Fr))) +
  geom_point()
```
